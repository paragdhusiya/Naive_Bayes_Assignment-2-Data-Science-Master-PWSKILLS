{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. A company conducted a survey of its employees and found that 70% of the employees use thecompany's health insurance plan, while 40% of the employees who use the plan are smokers. What is theprobability that an employee is a smoker given that he/she uses the health insurance plan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To find the probability that an employee is a smoker given that they use the health insurance plan, we can use Bayes' theorem.\n",
    "\n",
    "Let:\n",
    "\n",
    "Event \n",
    "𝑆\n",
    "S be the event that an employee is a smoker.\n",
    "Event \n",
    "𝐻\n",
    "H be the event that an employee uses the health insurance plan.\n",
    "We want to find \n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    "∣\n",
    "𝐻\n",
    ")\n",
    "P(S∣H), the probability that an employee is a smoker given that they use the health insurance plan.\n",
    "\n",
    "We are given:\n",
    "\n",
    "𝑃\n",
    "(\n",
    "𝐻\n",
    ")\n",
    "=\n",
    "0.70\n",
    "P(H)=0.70, the probability that an employee uses the health insurance plan.\n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    "∣\n",
    "𝐻\n",
    ")\n",
    "=\n",
    "0.40\n",
    "P(S∣H)=0.40, the probability that an employee is a smoker given that they use the health insurance plan.\n",
    "Using Bayes' theorem, we have:\n",
    "\n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    "∣\n",
    "𝐻\n",
    ")\n",
    "=\n",
    "𝑃\n",
    "(\n",
    "𝐻\n",
    "∣\n",
    "𝑆\n",
    ")\n",
    "⋅\n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    ")\n",
    "𝑃\n",
    "(\n",
    "𝐻\n",
    ")\n",
    "P(S∣H)= \n",
    "P(H)\n",
    "P(H∣S)⋅P(S)\n",
    "​\n",
    " \n",
    "\n",
    "We know that:\n",
    "\n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    ")\n",
    "P(S) is the probability that an employee is a smoker, which is not given directly in the problem. However, we can calculate it using the law of total probability.\n",
    "𝑃\n",
    "(\n",
    "𝐻\n",
    "∣\n",
    "𝑆\n",
    ")\n",
    "P(H∣S) is the probability that an employee uses the health insurance plan given that they are a smoker. This is given as \n",
    "0.40\n",
    "0.40 in the problem.\n",
    "We can calculate \n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    ")\n",
    "P(S) using the law of total probability:\n",
    "\n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    ")\n",
    "=\n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    "∣\n",
    "𝐻\n",
    ")\n",
    "⋅\n",
    "𝑃\n",
    "(\n",
    "𝐻\n",
    ")\n",
    "+\n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    "∣\n",
    "¬\n",
    "𝐻\n",
    ")\n",
    "⋅\n",
    "𝑃\n",
    "(\n",
    "¬\n",
    "𝐻\n",
    ")\n",
    "P(S)=P(S∣H)⋅P(H)+P(S∣¬H)⋅P(¬H)\n",
    "\n",
    "Where:\n",
    "\n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    "∣\n",
    "¬\n",
    "𝐻\n",
    ")\n",
    "P(S∣¬H) is the probability that an employee is a smoker given that they do not use the health insurance plan.\n",
    "𝑃\n",
    "(\n",
    "¬\n",
    "𝐻\n",
    ")\n",
    "P(¬H) is the probability that an employee does not use the health insurance plan, which is \n",
    "1\n",
    "−\n",
    "𝑃\n",
    "(\n",
    "𝐻\n",
    ")\n",
    "1−P(H).\n",
    "Given that \n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    "∣\n",
    "¬\n",
    "𝐻\n",
    ")\n",
    "P(S∣¬H) is not explicitly provided, we can't compute \n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    ")\n",
    "P(S) or \n",
    "𝑃\n",
    "(\n",
    "𝑆\n",
    "∣\n",
    "¬\n",
    "𝐻\n",
    ")\n",
    "P(S∣¬H).\n",
    "\n",
    "So, we can't directly compute the probability that an employee is a smoker given that they use the health insurance plan without more information.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The main difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the type of data they are designed to work with:\n",
    "\n",
    "Bernoulli Naive Bayes: This classifier is suitable for binary feature vectors, where each feature represents whether a particular term appears in a document (e.g., presence or absence of a term). It assumes that features are binary-valued.\n",
    "\n",
    "Multinomial Naive Bayes: This classifier is designed for multinomially distributed data, typically used for text classification tasks. It's suitable for features that represent counts or frequencies (e.g., word counts in documents). It assumes that features are multinomially distributed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. How does Bernoulli Naive Bayes handle missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "ernoulli Naive Bayes can handle missing values by treating them as another category or by using techniques \n",
    "like imputation to replace missing values with the mode or mean of the feature. However, since Bernoulli Naive Bayes assumes binary features, \n",
    "missing values might be encoded as a separate category (e.g., 0 for absence, 1 for presence).\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Can Gaussian Naive Bayes be used for multi-class classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification. It's commonly used when the \n",
    "features are continuous and assumed to follow a Gaussian distribution. In scikit-learn, \n",
    "the GaussianNB class supports multi-class classification out of the box.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This assignment involves implementing Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the scikit-learn library in Python. Additionally, 10-fold cross-validation is used to evaluate the performance of each classifier on the Spambase dataset obtained from the UCI Machine Learning Repository. The performance metrics reported include accuracy, precision, recall, and F1 score.\n",
    "\n",
    "Discussion:\n",
    "\n",
    "Performance: The performance of each classifier can be evaluated based on the reported metrics. It's important to analyze which variant of Naive Bayes performed the best in terms of these metrics.\n",
    "Reasons for Performance: The reasons behind the performance differences can be discussed. For example, Bernoulli Naive Bayes might perform better if the dataset consists of binary features, while Gaussian Naive Bayes might perform better if the features are continuous and approximately Gaussian distributed.\n",
    "Limitations: Any limitations observed during the evaluation, such as the assumption of feature independence in Naive Bayes or sensitivity to imbalanced data, should be discussed.\n",
    "Conclusion:\n",
    "\n",
    "Summary of Findings: Summarize the findings from the evaluation of the three Naive Bayes variants on the Spambase dataset.\n",
    "Suggestions for Future Work: Provide suggestions for future work, such as exploring ensemble methods or feature engineering techniques to improve classification performance. Additionally, discussing the potential impact of preprocessing steps or hyperparameter tuning on model performance can be beneficial.\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
